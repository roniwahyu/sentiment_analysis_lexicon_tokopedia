{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling with Inset Indonesia Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membaca dan menghapus duplikasi teks\n",
    "def read_and_remove_duplicates(input_file, text_column):\n",
    "    \"\"\"Membaca CSV dan menghapus duplikasi teks berdasarkan kolom teks kustom\"\"\"\n",
    "    df = pd.read_csv(input_file, encoding='utf-8')\n",
    "    df[text_column] = list(OrderedDict.fromkeys(df[text_column]))  # Menghapus duplikasi teks\n",
    "    return df\n",
    "\n",
    "# Fungsi untuk memuat leksikon kustom dan memperbarui SentimentIntensityAnalyzer\n",
    "def load_lexicons():\n",
    "    \"\"\"Memuat leksikon kustom dan memperbarui VADER SentimentIntensityAnalyzer\"\"\"\n",
    "    sia1A, sia1B, sia2 = SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer()\n",
    "    sia1A.lexicon.clear()\n",
    "    sia1B.lexicon.clear()\n",
    "    sia2.lexicon.clear()\n",
    "\n",
    "    # Memuat leksikon InSet dan SentiWords\n",
    "    with open('../leksikon/inset/_json_inset-neg.txt') as f1A, \\\n",
    "         open('../leksikon/inset/_json_inset-pos.txt') as f1B, \\\n",
    "         open('../leksikon/sentistrength_id/_json_sentiwords_id.txt') as f2:\n",
    "        insetNeg = json.load(f1A)\n",
    "        insetPos = json.load(f1B)\n",
    "        senti = json.load(f2)\n",
    "    \n",
    "    # Update leksikon ke analyzer\n",
    "    sia1A.lexicon.update(insetNeg)\n",
    "    sia1B.lexicon.update(insetPos)\n",
    "    sia2.lexicon.update(senti)\n",
    "\n",
    "    return sia1A, sia1B, sia2\n",
    "\n",
    "# Fungsi untuk menentukan apakah sentimen positif berdasarkan leksikon InSet\n",
    "def is_positive_inset(tweet, sia1A, sia1B):\n",
    "    \"\"\"Mengembalikan True jika tweet memiliki sentimen positif\"\"\"\n",
    "    return sia1A.polarity_scores(tweet)[\"compound\"] + sia1B.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "# Fungsi untuk menentukan apakah sentimen positif berdasarkan SentiWords\n",
    "def is_positive_senti(tweet, sia2):\n",
    "    \"\"\"Mengembalikan True jika tweet memiliki sentimen positif\"\"\"\n",
    "    return sia2.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "# Fungsi untuk menerapkan label berdasarkan analisis sentimen\n",
    "def apply_sentiment_label(df, sia1A, sia1B, sia2, text_column):\n",
    "    \"\"\"Menerapkan label sentimen ke DataFrame berdasarkan leksikon\"\"\"\n",
    "    df['label_inset'] = df[text_column].apply(lambda tweet: 'pos' if is_positive_inset(tweet, sia1A, sia1B) else 'neg')\n",
    "    df['label_senti'] = df[text_column].apply(lambda tweet: 'pos' if is_positive_senti(tweet, sia2) else 'neg')\n",
    "    return df\n",
    "\n",
    "# Fungsi utama untuk pipeline pemrosesan dengan kolom teks kustom\n",
    "def process_text(input_csv, output_csv, text_column):\n",
    "    \"\"\"Pipeline utama untuk memproses teks dan memberikan label sentimen berdasarkan kolom teks kustom\"\"\"\n",
    "    \n",
    "    # Membaca teks dan menghapus duplikasi\n",
    "    df = read_and_remove_duplicates(input_csv, text_column)\n",
    "    \n",
    "    # Memuat leksikon dan SentimentIntensityAnalyzer\n",
    "    sia1A, sia1B, sia2 = load_lexicons()\n",
    "    \n",
    "    # Menerapkan label sentimen ke DataFrame\n",
    "    df = apply_sentiment_label(df, sia1A, sia1B, sia2, text_column)\n",
    "    \n",
    "    # Menyimpan hasil ke CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Hasil disimpan di {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_text() missing 1 required positional argument: 'text_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m06_hasil_labeling.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Jalankan pipeline\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m text_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_steamindo\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Kolom teks yang akan digunakan (custom)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Jalankan pipeline dengan kolom teks kustom\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: process_text() missing 1 required positional argument: 'text_column'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path input dan output file CSV\n",
    "input_csv = '05_hasil_stemming_indo.csv'\n",
    "output_csv = '06_hasil_labeling.csv'\n",
    "\n",
    "# Jalankan pipeline\n",
    "process_text(input_csv, output_csv)\n",
    "text_column = 'text_steamindo'  # Kolom teks yang akan digunakan (custom)\n",
    "\n",
    "# Jalankan pipeline dengan kolom teks kustom\n",
    "process_text(input_csv, output_csv, text_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
